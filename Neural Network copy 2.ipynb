{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3487915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa826ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, row, col):\n",
    "        self.outputs = []\n",
    "        self.errorWRTnet = []\n",
    "        self.gradiants = []\n",
    "        self.init(row, col)\n",
    "    \n",
    "    def init(self, row, col):\n",
    "        self.weights = np.random.rand(row, col)\n",
    "        self.biases = np.zeros(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56b28645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.layers = []\n",
    "    \n",
    "    def initLayers(self):\n",
    "        # Initializing all layers\n",
    "        for i in range(len(self.sizes)):\n",
    "            layer = Layer(self.sizes[i], self.sizes[i-1])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def setLearningRate(self, learningR):\n",
    "        self.learningR = learningR\n",
    "\n",
    "    def setEpoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "    \n",
    "    def feedForward(self, input):\n",
    "        # feeding all layers\n",
    "        outputs = input\n",
    "        self.layers[0].outputs = outputs\n",
    "        for i in range(1, len(self.sizes)):\n",
    "            outputs = np.dot(outputs, self.layers[i].weights.T)\n",
    "            outputs = self.activation(outputs)\n",
    "            self.layers[i].outputs = outputs\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def activation(self, outputs):\n",
    "        outputs = np.clip(outputs, -500, 500)\n",
    "        return 1/(1 + np.exp(-outputs))\n",
    "    \n",
    "    def claculateError(self, outputs, targets):\n",
    "        error = np.square(np.subtract(targets, outputs)).mean()\n",
    "        return error\n",
    "    \n",
    "    def backPropagation(self, outputs, targets):\n",
    "        # Backpropagation for the output layer\n",
    "        errorWRToutput = np.subtract(targets, outputs)\n",
    "        outWRTnet = np.multiply(outputs, np.subtract(1, outputs))\n",
    "        errorWRTnet = np.multiply(errorWRToutput, outWRTnet)\n",
    "        self.layers[len(self.sizes)-1].errorWRTnet = errorWRTnet\n",
    "        netWRTweight = self.layers[len(self.sizes)-2].outputs\n",
    "        errorWRTweight = np.multiply(netWRTweight, np.transpose([errorWRTnet]))\n",
    "        self.layers[len(self.sizes)-1].gradiants = errorWRTweight\n",
    "\n",
    "        # Backpropagation for the hidden layers\n",
    "        for i in reversed(range(1, len(self.sizes)-1)):\n",
    "            errorWRToutput = np.dot(self.layers[i+1].errorWRTnet, self.layers[i+1].weights)\n",
    "            outWRTnet = np.multiply(self.layers[i].outputs, np.subtract(1, self.layers[i].outputs))\n",
    "            errorWRTnet = np.multiply(errorWRToutput, outWRTnet)\n",
    "            self.layers[i].errorWRTnet = errorWRTnet\n",
    "            netWRTweight = self.layers[i-1].outputs\n",
    "            errorWRTweight = np.multiply(netWRTweight, np.transpose([errorWRTnet]))\n",
    "            self.layers[i].gradiants = errorWRTweight\n",
    "        \n",
    "        self.updateWeights()\n",
    "\n",
    "    def updateWeights(self):\n",
    "        for i in reversed(range(1, len(self.sizes))):\n",
    "            np.subtract(self.layers[i].weights, self.layers[i].gradiants)\n",
    "    \n",
    "    def trainModel(self, inputs, targets):\n",
    "        for i in range(self.epoch):\n",
    "            for input, target in zip(inputs, targets):\n",
    "                output = self.feedForward(input)\n",
    "                self.backPropagation(output, target)\n",
    "        print('Training completed')\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.feedForward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 4, 4, 7]\n",
    "y = [2, 6, 3]\n",
    "\n",
    "print(np.multiply(x, np.transpose([y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [np.random.rand(5)]\n",
    "targets = [[0, 1, 0]]\n",
    "network = NeuralNetwork([5, 4, 4, 4, 3])\n",
    "network.initLayers()\n",
    "network.setEpoch(5)\n",
    "network.setLearningRate(.01)\n",
    "network.trainModel(inputs, targets)\n",
    "for i in range(1, len(network.sizes)):\n",
    "    print(network.layers[i].gradiants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3eec6905afc42fe5cdadc178736cc93ef800e9ca9362a6d50a5159adfbee55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
