{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3487915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa826ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definging layer class\n",
    "class Layer:\n",
    "    def __init__(self, row, col):\n",
    "        # to store outputs after activations\n",
    "        self.outputs = []\n",
    "        # to store derivative with respect to net input\n",
    "        self.errorWRTnet = []\n",
    "        self.init(row, col)\n",
    "    \n",
    "    def init(self, row, col):\n",
    "        self.weights = np.random.randn(row, col)\n",
    "        self.biases = np.zeros(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b28645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.layers = []\n",
    "    \n",
    "    def initLayers(self):\n",
    "        # Initializing all layers\n",
    "        # for 1st layer we don't need weights and biases but for our \n",
    "        # convenience we are doing so\n",
    "        self.layers.append(Layer(self.sizes[0], 1))\n",
    "        for i in range(1, len(self.sizes)):\n",
    "            layer = Layer(self.sizes[i], self.sizes[i-1])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def setLearningRate(self, learningR):\n",
    "        self.learningR = learningR\n",
    "\n",
    "    def feedForward(self, inputs):\n",
    "        # feeding all layers\n",
    "        outputs = inputs\n",
    "        # storing the inputs as outputs for using in backpropagations\n",
    "        self.layers[0].outputs = outputs\n",
    "        for i in range(1, len(self.sizes)):\n",
    "            outputs = np.dot(outputs, self.layers[i].weights.T)\n",
    "            outputs = self.activation(outputs)\n",
    "            self.layers[i].outputs = outputs\n",
    "        return outputs\n",
    "\n",
    "    def activation(self, outputs):\n",
    "        outputs = np.clip(outputs, -500, 500)\n",
    "        return 1/(1 + np.exp(-outputs))\n",
    "    \n",
    "    # function to calculate mean squared error\n",
    "    def claculateError(self, outputs, targets):\n",
    "        error = np.square(np.subtract(targets, outputs)).mean()\n",
    "        return error\n",
    "    \n",
    "    def backPropagation(self, outputs, targets):\n",
    "        # array to store gradients for each layer\n",
    "        gradients = [None]*len(self.sizes)\n",
    "\n",
    "        # Backpropagation for the output layer\n",
    "        errorWRToutput = np.subtract(outputs, targets)\n",
    "        outWRTnet = np.multiply(outputs, 1 - outputs)\n",
    "        errorWRTnet = np.multiply(errorWRToutput, outWRTnet)\n",
    "        self.layers[len(self.sizes)-1].errorWRTnet = errorWRTnet\n",
    "        netWRTweight = self.layers[len(self.sizes)-2].outputs\n",
    "        errorWRTweight = np.multiply(netWRTweight, np.transpose([errorWRTnet]))\n",
    "        gradients[len(self.sizes)-1] = errorWRTweight\n",
    "\n",
    "        # Backpropagation for the hidden layers\n",
    "        for i in reversed(range(1, len(self.sizes)-1)):\n",
    "            errorWRToutput = np.dot(self.layers[i+1].errorWRTnet, self.layers[i+1].weights)\n",
    "            outWRTnet = np.multiply(self.layers[i].outputs, 1 - self.layers[i].outputs)\n",
    "            errorWRTnet = np.multiply(errorWRToutput, outWRTnet)\n",
    "            self.layers[i].errorWRTnet = errorWRTnet\n",
    "            netWRTweight = self.layers[i-1].outputs\n",
    "            errorWRTweight = np.multiply(netWRTweight, np.transpose([errorWRTnet]))\n",
    "            gradients[i] = errorWRTweight\n",
    "        return gradients\n",
    "\n",
    "    def updateWeights(self, gradients):\n",
    "        for i in reversed(range(1, len(self.sizes))):\n",
    "            newWeights = self.layers[i].weights - self.learningR*gradients[i]\n",
    "            self.layers[i].weights = newWeights\n",
    "\n",
    "    def trainModel(self, inputs, targets):\n",
    "        for i in range(5):\n",
    "            for input, target in zip(inputs, targets):\n",
    "                output = self.feedForward(input)\n",
    "                gradients = self.backPropagation(output, target)\n",
    "                self.updateWeights(gradients)\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.feedForward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training dataset\n",
    "df = pd.read_csv('./dataset/mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating label and features data\n",
    "labels = df.iloc[:, 0].values\n",
    "inputs = df.iloc[:, 1:].values\n",
    "\n",
    "# converting labels to one hot\n",
    "oneHots = np.zeros((labels.size, 10))\n",
    "rows = np.arange(labels.size)\n",
    "oneHots[rows, labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main part of building the model\n",
    "network = NeuralNetwork([784, 50, 50, 50, 50, 10])\n",
    "network.initLayers()\n",
    "network.setLearningRate(.01)\n",
    "network.trainModel(inputs, oneHots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69811027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the training again manually\n",
    "network.trainModel(inputs, oneHots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ac1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing error of the model\n",
    "for input, label in zip(inputs[:100], oneHots[:100]):\n",
    "    output = network.feedForward(input)\n",
    "    print(network.claculateError(output, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset for testing\n",
    "df2 = pd.read_csv('./dataset/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed112199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the features and labels\n",
    "labels2 = df2.iloc[:100, 0].values\n",
    "inputs2 = df2.iloc[:100, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "for input, label in zip(inputs2, labels2):\n",
    "    output = network.feedForward(input)\n",
    "    print('label:', label, 'result:', np.argmax(output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3eec6905afc42fe5cdadc178736cc93ef800e9ca9362a6d50a5159adfbee55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
